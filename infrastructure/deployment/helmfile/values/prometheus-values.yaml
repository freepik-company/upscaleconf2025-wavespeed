# Prometheus configuration for WaveSpeed Workshop

## Global settings
global:
  evaluation_interval: 30s
  scrape_interval: 10s
  scrape_timeout: 10s

## Server configuration
server:
  persistentVolume:
    enabled: true
    size: 8Gi
  resources:
    limits:
      memory: 1Gi
      cpu: 500m
    requests:
      memory: 512Mi
      cpu: 200m
  # Ensure no authentication is enabled
  enableAdminApi: true

## Configure Alertmanager
alertmanager:
  enabled: true
  persistentVolume:
    enabled: true
    size: 2Gi

## Disable PodSecurityPolicy (not supported in newer Kubernetes versions)
rbac:
  create: true
  pspEnabled: false

## Prometheus service monitors
serviceMonitors:
  # Redis monitoring
  - name: redis
    enabled: true
    selector:
      matchLabels:
        app.kubernetes.io/name: redis
    namespaceSelector:
      matchNames:
        - workshop
    endpoints:
      - port: metrics
        interval: 10s
        path: /metrics
        
  # Celery monitoring
  - name: celery
    enabled: true
    selector:
      matchLabels:
        app.kubernetes.io/name: celery-app
    namespaceSelector:
      matchNames:
        - workshop
    endpoints:
      - port: metrics
        interval: 10s
        path: /metrics
        
  # Istio monitoring
  - name: istio-component-monitor
    enabled: true
    selector:
      matchExpressions:
        - {key: istio, operator: In, values: [pilot]}
    namespaceSelector:
      matchNames:
        - istio-system
    endpoints:
      - port: http-monitoring
        interval: 15s

## Additional scrape configs for Redis metrics
extraScrapeConfigs: |
  - job_name: 'redis-metrics'
    scrape_interval: 10s
    kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
            - workshop
    relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name]
        regex: redis
        action: keep
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        regex: metrics
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_service_name]
        target_label: service
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
  
  # Celery metrics scrape configuration
  - job_name: 'celery-metrics'
    scrape_interval: 10s
    metrics_path: /metrics
    kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
            - workshop
    relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name]
        regex: celery-app
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_service_name]
        target_label: service
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      - source_labels: [__meta_kubernetes_pod_label_component]
        target_label: component
        
  # Inference Balancer NGINX metrics
  - job_name: 'nginx-balancer-metrics'
    scrape_interval: 10s
    metrics_path: /metrics
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - inference-balancer
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        regex: true
        action: keep
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        regex: (.+)
        target_label: __metrics_path__
        action: replace
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        regex: ([^:]+)(?::\d+)?;(\d+)
        target_label: __address__
        replacement: $1:$2
        action: replace
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
        target_label: component
      - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_instance]
        target_label: instance
        
  # Istio Envoy Sidecar metrics for inference-balancer
  - job_name: 'istio-proxy-inference-balancer'
    scrape_interval: 10s
    metrics_path: /stats/prometheus
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - inference-balancer
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_container_name]
        regex: istio-proxy
        action: keep
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod_name
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_label_app]
        action: replace
        target_label: app
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        regex: (.*)
        target_label: instance

  # Istio control plane metrics
  - job_name: 'istio-telemetry'
    scrape_interval: 15s
    scheme: http
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - istio-system
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_istio]
        regex: pilot
        action: keep
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod_name
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace

## Prometheus alerting rules
serverFiles:
  alerting_rules.yml:
    groups:
      - name: redis-alerts
        rules:
          - alert: RedisDown
            expr: redis_up == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "Redis instance is down"
              description: "Redis instance {{ $labels.instance }} is down"
          - alert: RedisHighMemory
            expr: redis_memory_used_bytes / redis_total_system_memory_bytes * 100 > 80
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Redis high memory usage"
              description: "Redis instance {{ $labels.instance }} memory usage is over 80%"
      
      - name: nginx-alerts
        rules:
          - alert: NginxDown
            expr: nginx_up == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "NGINX instance is down"
              description: "NGINX instance {{ $labels.instance }} is down"
          - alert: NginxHighConnections
            expr: nginx_connections_active > 500
            for: 1m
            labels:
              severity: warning
            annotations:
              summary: "NGINX high connection count"
              description: "NGINX instance {{ $labels.instance }} has high active connections ({{ $value }})"
              
      - name: istio-alerts
        rules:
          - alert: IstioHighRequestLatency
            expr: istio_request_duration_milliseconds_sum{app="inference-balancer"} / istio_request_duration_milliseconds_count{app="inference-balancer"} > 500
            for: 1m
            labels:
              severity: warning
            annotations:
              summary: "High request latency on {{ $labels.destination_service }}"
              description: "Request latency for destination {{ $labels.destination_service }} is {{ $value }}ms"
          - alert: IstioHighErrorRate
            expr: rate(istio_requests_total{reporter="destination", response_code=~"5.*", destination_service=~".*inference-balancer.*"}[5m]) / rate(istio_requests_total{reporter="destination", destination_service=~".*inference-balancer.*"}[5m]) * 100 > 5
            for: 1m
            labels:
              severity: warning
            annotations:
              summary: "High error rate for {{ $labels.destination_service }}"
              description: "Error rate for {{ $labels.destination_service }} is {{ $value }}%" 