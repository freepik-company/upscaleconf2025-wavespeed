apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "inference-balancer.fullname" . }}-main
  namespace: {{ .Values.namespace }}
  labels:
    {{- include "inference-balancer.labels" . | nindent 4 }}
    app.kubernetes.io/component: main-loadbalancer
spec:
  replicas: {{ .Values.mainLoadBalancer.replicaCount }}
  selector:
    matchLabels:
      {{- include "inference-balancer.selectorLabels" . | nindent 6 }}
      app.kubernetes.io/component: main-loadbalancer
  template:
    metadata:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "80"
        prometheus.io/path: "/metrics"
      labels:
        {{- include "inference-balancer.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: main-loadbalancer
    spec:
      containers:
        - name: {{ .Chart.Name }}-main
          image: "{{ .Values.mainLoadBalancer.image.repository }}:{{ .Values.mainLoadBalancer.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.mainLoadBalancer.image.pullPolicy }}
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
          resources:
            {{- toYaml .Values.mainLoadBalancer.resources | nindent 12 }}
          volumeMounts:
            - name: nginx-config
              mountPath: /etc/nginx/nginx.conf
              subPath: nginx.conf
            - name: nginx-logs
              mountPath: /var/log/nginx
        
        # Metrics exporter sidecar
        - name: metrics-exporter
          image: "nginx/nginx-prometheus-exporter:1.3.0"
          imagePullPolicy: IfNotPresent
          args:
            - -nginx.scrape-uri=http://localhost:80/metrics
            - -web.telemetry-path=/metrics
            - -web.listen-address=:9113
          ports:
            - name: metrics
              containerPort: 9113
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /metrics
              port: metrics
            initialDelaySeconds: 10
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /metrics
              port: metrics
            initialDelaySeconds: 5
            periodSeconds: 10
            
        # Static metrics for service tracking
        - name: log-exporter
          image: "nginx:alpine"
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
            - -c
            - |
              # Create metrics file with static data to demonstrate concept
              mkdir -p /usr/share/nginx/html
              cat > /usr/share/nginx/html/metrics << EOF
              # HELP nginx_upstream_requests_total Total number of requests by upstream service
              # TYPE nginx_upstream_requests_total counter
              nginx_upstream_requests_total{service="a",status="200"} 95
              nginx_upstream_requests_total{service="b",status="200"} 4 
              nginx_upstream_requests_total{service="c",status="200"} 1
              
              # HELP nginx_upstream_response_time_seconds Response time by upstream service
              # TYPE nginx_upstream_response_time_seconds histogram
              nginx_upstream_response_time_seconds_bucket{service="a",status="200",le="0.001"} 15
              nginx_upstream_response_time_seconds_bucket{service="a",status="200",le="0.01"} 55
              nginx_upstream_response_time_seconds_bucket{service="a",status="200",le="0.1"} 95
              nginx_upstream_response_time_seconds_bucket{service="a",status="200",le="+Inf"} 95
              nginx_upstream_response_time_seconds_count{service="a",status="200"} 95
              nginx_upstream_response_time_seconds_sum{service="a",status="200"} 3.2
              
              nginx_upstream_response_time_seconds_bucket{service="b",status="200",le="0.001"} 0
              nginx_upstream_response_time_seconds_bucket{service="b",status="200",le="0.01"} 1
              nginx_upstream_response_time_seconds_bucket{service="b",status="200",le="0.1"} 4
              nginx_upstream_response_time_seconds_bucket{service="b",status="200",le="+Inf"} 4
              nginx_upstream_response_time_seconds_count{service="b",status="200"} 4
              nginx_upstream_response_time_seconds_sum{service="b",status="200"} 0.15
              
              nginx_upstream_response_time_seconds_bucket{service="c",status="200",le="0.001"} 0
              nginx_upstream_response_time_seconds_bucket{service="c",status="200",le="0.01"} 0
              nginx_upstream_response_time_seconds_bucket{service="c",status="200",le="0.1"} 1
              nginx_upstream_response_time_seconds_bucket{service="c",status="200",le="+Inf"} 1
              nginx_upstream_response_time_seconds_count{service="c",status="200"} 1
              nginx_upstream_response_time_seconds_sum{service="c",status="200"} 0.05
              EOF
              
              # Create nginx config for metrics endpoint
              cat > /etc/nginx/conf.d/default.conf << EOF
              server {
                  listen 9090;
                  
                  location /metrics {
                      default_type text/plain;
                      root /usr/share/nginx/html;
                  }
                  
                  location / {
                      return 301 /metrics;
                  }
              }
              EOF
              
              # Start nginx
              nginx -g "daemon off;"
          ports:
            - name: log-metrics
              containerPort: 9090
              protocol: TCP
      volumes:
        - name: nginx-config
          configMap:
            name: {{ include "inference-balancer.fullname" . }}-main-config
        - name: nginx-logs
          persistentVolumeClaim:
            claimName: {{ include "inference-balancer.fullname" . }}-nginx-logs 